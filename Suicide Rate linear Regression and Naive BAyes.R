suicidal_data<- read.csv("C:\\Users\\Evlin Emmanuel\\Desktop\\MSC DATA ANALYTICS\\Data Mining and Machine Learning 1\\project datasets\\suicide rate\\master.csv",stringsAsFactors = FALSE)
head(suicidal_data)
cleaned_data<-na.omit(suicidal_data)
cleaned_data
names(cleaned_data)

suicidal_data$sex <- factor(suicidal_data$sex, levels = c("M", "F"))
suicidal_data$age<-as.factor(suicidal_data$age)
suicidal_data$generation<-as.factor(suicidal_data$generation)


#alias(clean_data)
str(cleaned_data)

#splitting the data into train and test
set.seed(2)
library(caTools)
partition<-sample.split(cleaned_data,SplitRatio = 0.7)
train_data<-subset(cleaned_data,partition=="TRUE")
test_data<-subset(cleaned_data,partition=="FALSE")

#CREATE THE MODEL
model<-lm(suicides_no~sex+age+generation+population,data=train_data)#training the model
summary(model)


#prediction

predict_data<-predict(model,test_data)

#comparing predicted vs actual values
plot(cleaned_data$suicides_no,type="l",lty=1.8,col="blue") #actual
lines(predict_data,type = "l",col="red") #predicted
plot(predict_data,type = "l",lty=1.8,col="blue")

#finding accuracy
rmse<-sqrt(mean(predict_data-cleaned_data$suicides_no)^2)
rmse



#####################Naive Baise#############################


# NAIVE BAYES #

# load mlbench library
library(mlbench)

suicidal_data

head(suicidal_data,10)
any(is.na(suicidal_data))
clean_suicide_data<-na.omit(suicidal_data)
any(is.na(clean_suicide_data))


clean_suicide_data[,"train"] <- ifelse(runif(nrow(clean_suicide_data))<0.75,1,0)

clean_suicide_data$train = as.factor(clean_suicide_data$train)
clean_suicide_data$HDI.for.year = as.factor(clean_suicide_data$HDI.for.year)
traincolum_Num <- grep('train', names(clean_suicide_data))
print(traincolum_Num)


# Separating training set and test set
train <- clean_suicide_data[clean_suicide_data$train==1,-traincolum_Num]
test <- clean_suicide_data[clean_suicide_data$train==0,-traincolum_Num]
summary(clean_suicide_data)

# Invoking naiveBayes method.
library(e1071)
output <- naiveBayes(HDI.for.year~.,data = train)
output
str(output)
summary(output)
nb_test_predict <-predict(output,test[-5]) #Removing class attribute


library(caret)
p1<-predict(output,train)
p1# to view predicted  values
head(train$suicides_no)#to view actual values
confusionMatrix(p1,train$suicides_no)

# Building confusion matrix
table(pred=nb_test_predict,true=test$HDI.for.year)

# The confusion matrix has two dimensions: one which holds actual value and the other that holds
# predicted values. The confusion matrix generated by the formula above sums up the 
# performance of our Naive Bayes algorithm. It shows how most of the probabilities have 
# been given the value of 0, which is not a good indication. If the predictions had been 
# assigned the value of 1, we could haveconcluded that the Naive Bayes model is good for 
# the dataset.
